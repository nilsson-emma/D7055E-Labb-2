{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot as gplt # Geoplot: Library for high-level geospatial data visualization\n",
    "import geopandas as gpd # GeoPandas: Extends pandas to handle geometric/geographic data\n",
    "import geoplot.crs as gcrs # Geoplot color ramp schemes for geographic visualizations\n",
    "import imageio # Imageio: Library for reading and writing image data\n",
    "import pandas as pd # Pandas: Data manipulation and analysis library\n",
    "import pathlib # Pathlib: Object-oriented filesystem paths\n",
    "import matplotlib.animation as animation # Matplotlib animation: For creating animated visualizations\n",
    "import matplotlib.pyplot as plt # Matplotlib pyplot: Plotting library for creating static visualizations\n",
    "import mapclassify as mc # Mapclassify: Classification schemes for choropleth maps\n",
    "import numpy as np # NumPy: Library for numerical computing in Python\n",
    "import pycountry # Pycountry: Database of country information (names, ISO codes, etc.)\n",
    "import plotly.express as px # Plotly Express: High-level interface for creating interactive plots\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = gpd.read_file(\"C:\\\\Users\\\\emmae\\\\Desktop\\\\DataVisualization_Uppgiftsmapp\\\\Labb2\\\\3.3NationalObesityByState\\\\us_state.shp\")\n",
    "print(usa.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop = pd.read_csv(\"C:\\\\Users\\\\emmae\\\\Desktop\\\\DataVisualization_Uppgiftsmapp\\\\Labb2\\\\3.3GeospatialDataVisualization\\\\us_state_est_population.csv\")\n",
    "print(state_pop.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Couples state name and region name\n",
    "pop_states = usa.merge(state_pop, left_on=\"StateName\", right_on=\"NAME\")\n",
    "pop_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gplt.datasets.get_path(\"contiguous_usa\")\n",
    "contiguous_usa = gpd.read_file(path)\n",
    "contiguous_usa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5.2.13 Another sample dataset, in this case for US cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gplt.datasets.get_path(\"usa_cities\")\n",
    "usa_cities = gpd.read_file(path)\n",
    "usa_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continental_usa_cities = usa_cities.query('STATE not in [\"HI\", \"AK\", \"PR\"]')\n",
    "gplt.pointplot(continental_usa_cities, s=3, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.polyplot(contiguous_usa)\n",
    "gplt.pointplot(continental_usa_cities, s=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.polyplot(contiguous_usa, projection=gcrs.AlbersEqualArea())\n",
    "gplt.pointplot(continental_usa_cities, s= 1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions of the grid\n",
    "rows = 10\n",
    "columns = 15\n",
    "\n",
    "# Create a 2D coordinate grid using meshgrid\n",
    "x, y = np.meshgrid(np.linspace(-1,1,columns), np.linspace(-1,1,rows))\n",
    "\n",
    "# Calculate the distance from origin (0,0) for each point using Pythagorean theorem\n",
    "d = np.sqrt(x*x+y*y)\n",
    "\n",
    "# Define standard deviation for the Gaussian distribution\n",
    "sigma = 0.5\n",
    "\n",
    "# Create a 2D Gaussian disc:\n",
    "disc = (8*np.exp(-( (d)**2 / ( 2.0 * sigma**2 ) ))).astype('uint')\n",
    "\n",
    "# Create an RGB color array by stacking three versions of the disc:\n",
    "# Original disc for red channel\n",
    "# Rolled (shifted) disc by 2 positions along axis 0 for green channel\n",
    "# Rolled disc by 2 positions along axis 1 for blue channel\n",
    "# axis=2 means we're stacking these as color channels (R,G,B)\n",
    "myRGBColorArray = np.stack((disc,np.roll(disc,2,axis=0),np.roll(disc,2,axis=1)),axis=2)\n",
    "\n",
    "# Print and display the Green channel (index 1) of the RGB array\n",
    "print(\"Green:\")\n",
    "display(myRGBColorArray[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.polyplot(\n",
    "    contiguous_usa,\n",
    "    edgecolor=\"white\",\n",
    "    facecolor=\"lightgray\",\n",
    "    figsize=(12, 8),\n",
    "    projection=gcrs.AlbersEqualArea()\n",
    ")\n",
    "\n",
    "gplt.pointplot(\n",
    "    continental_usa_cities,\n",
    "    ax=ax,\n",
    "    hue=\"ELEV_IN_FT\",\n",
    "    cmap=\"Blues\",\n",
    "    scheme=\"quantiles\",\n",
    "    scale=\"ELEV_IN_FT\",\n",
    "    limits=(1, 10),\n",
    "    legend=True,\n",
    "    legend_var=\"scale\",\n",
    "    legend_kwargs={\"frameon\": False},\n",
    "    legend_values=[-110, 1750, 3600, 5500, 7400],\n",
    "    legend_labels=[\"-110 feet\", \"1750 feet\", \"3600 feet\", \"5500 feet\", \"7400 feet\"]\n",
    ")\n",
    "\n",
    "ax.set_title(\"Cities in the continental US, by elevation\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.polyplot(contiguous_usa, projection=gcrs.AlbersEqualArea())\n",
    "gplt.choropleth(\n",
    "    contiguous_usa,\n",
    "    hue=\"population\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    "    cmap=\"Greens\",\n",
    "    legend=True,\n",
    "    scheme=\"FisherJenks\",\n",
    "    legend_labels=[\n",
    "        \"<3 million\", \"3-6.7 million\", \"6.7-12.8 million\",\n",
    "        \"12.8-25 million\", \"25-37 million\"\n",
    "    ],\n",
    "    projection=gcrs.AlbersEqualArea(),\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmedGlobal = pd.read_csv(\"C:\\\\Users\\\\emmae\\\\Desktop\\\\DataVisualization_Uppgiftsmapp\\\\Labb2\\\\3.4Covid-19\\\\time_series_covid19_confirmed_global.csv\")\n",
    "print(df_confirmedGlobal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns and sum by country\n",
    "df_confirmedGlobal = df_confirmedGlobal.drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "df_confirmedGlobal = df_confirmedGlobal.groupby('Country/Region').agg('sum')\n",
    "date_list = list(df_confirmedGlobal.columns)\n",
    "\n",
    "# Function to get three-letter country codes\n",
    "def get_country_code(name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_3\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Add country codes to the dataset\n",
    "df_confirmedGlobal['country'] = df_confirmedGlobal.index\n",
    "df_confirmedGlobal['iso_alpha_3'] = df_confirmedGlobal['country'].apply(get_country_code)\n",
    "\n",
    "# Transform to long format\n",
    "df_long = pd.melt(df_confirmedGlobal, \n",
    "                  id_vars=['country', 'iso_alpha_3'], \n",
    "                  value_vars=date_list)\n",
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(df_long,\n",
    "                    locations=\"iso_alpha_3\",\n",
    "                    color=\"value\",\n",
    "                    hover_name=\"country\",\n",
    "                    animation_frame=\"variable\",\n",
    "                    projection=\"natural earth\",\n",
    "                    color_continuous_scale='Peach',\n",
    "                    range_color=[0, 50000]\n",
    "                    )\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"Covid19_map.html\") # write it to HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Part#3: Challenging Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Use “myRGBColorArray” from step5 in subsection Visualizing Spatial Data and\n",
    "display individual channels as well as Composite accordingly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 4 subplots\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Display the Red channel\n",
    "axes[0].imshow(myRGBColorArray[:, :, 0], cmap='Reds')\n",
    "axes[0].set_title('Red Channel')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display the Green channel\n",
    "axes[1].imshow(myRGBColorArray[:, :, 1], cmap='Greens')\n",
    "axes[1].set_title('Green Channel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Display the Blue channel\n",
    "axes[2].imshow(myRGBColorArray[:, :, 2], cmap='Blues')\n",
    "axes[2].set_title('Blue Channel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Display the Composite image\n",
    "axes[3].imshow(myRGBColorArray)\n",
    "axes[3].set_title('Composite Image')\n",
    "axes[3].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10\n",
    "columns = 15\n",
    "x, y = np.meshgrid(np.linspace(-1, 1, columns), np.linspace(-1, 1, rows))\n",
    "sigma = 0.5\n",
    "d = np.sqrt(x**2 + y**2)\n",
    "disc = (8 * np.exp(-(d**2 / (2.0 * sigma**2)))).astype('float32')  # Använd float för mer kontroll\n",
    "\n",
    "#Normalisera disken mellan 0 och 255\n",
    "disc = 255 * (disc / disc.max())\n",
    "\n",
    "#Skapa RGB-array\n",
    "myRGBColorArray = np.stack([\n",
    "    disc,                     # Röd kanal\n",
    "    np.roll(disc, 2, axis=0), # Grön kanal\n",
    "    np.roll(disc, 2, axis=1)  # Blå kanal\n",
    "], axis=2).astype('uint8')\n",
    "\n",
    "#Visa bilderna\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "#Röd kanal\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Red Channel\")\n",
    "plt.imshow(myRGBColorArray[:, :, 0], cmap='Reds')\n",
    "plt.axis('off')\n",
    "\n",
    "#Grön kanal\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Green Channel\")\n",
    "plt.imshow(myRGBColorArray[:, :, 1], cmap='Greens')\n",
    "plt.axis('off')\n",
    "\n",
    "#Blå kanal\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Blue Channel\")\n",
    "plt.imshow(myRGBColorArray[:, :, 2], cmap='Blues')\n",
    "plt.axis('off')\n",
    "\n",
    "#Kombinerad RGB-bild som blir helsvart\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Composite RGB colorful\")\n",
    "plt.imshow(myRGBColorArray)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three subplots display when the emphasis is on one out of the three possible channels, either red, green or blue. The fourth subplot, the composite subplot, is made from all three channels. In our first code the composite subplot was all blanck and in the second it was more colorful. We added the second composite subplot in order to make it more esthetically appealing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. What is quantile? How does the number of quantiles affect the visualization? (write\n",
    "3-5 sentences)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quantile divides a dataset into equal-sized subsets based on the data's distribution. The number of quantiles determines how finely the data is partitioned and affect how patterns/distributions are visualized. When fewer quantiles are used (e.g., quartiles), the visualization highlights broader trends, making it easier to observe general patterns but not finer details. Conversely, using many quantiles reveals more nuanced or subtle variations in the data, but can make the visualization cluttered and harder to interpret. By adjusting the number of quantiles, you balance between simplicity and detail in your visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. Divide the continental_usa_cities into 10 quantiles and assign a different hue to each\n",
    "quantile and a legend to explain accordingly. Produce a point plot or similar plot and\n",
    "explain the representation difference in your own words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Classify the data into 10 quantiles\n",
    "quantiles = mc.Quantiles(continental_usa_cities['ELEV_IN_FT'], k=10)\n",
    "\n",
    "# Add the quantile classification to the dataframe\n",
    "continental_usa_cities['quantiles'] = quantiles.yb\n",
    "\n",
    "# Create the plot\n",
    "ax = gplt.polyplot(contiguous_usa, projection=gcrs.AlbersEqualArea())\n",
    "gplt.pointplot(\n",
    "    continental_usa_cities,\n",
    "    ax=ax,\n",
    "    hue='quantiles',\n",
    "    cmap='viridis',\n",
    "    legend=False,\n",
    "    #legend_var='hue',\n",
    "    s=1\n",
    ")\n",
    "\n",
    "# Create a custom legend\n",
    "cmap = plt.cm.viridis\n",
    "norm = mcolors.Normalize(vmin=0, vmax=9)  # Quantiles range from 0 to 9\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Required for the colorbar to function\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation=\"vertical\", pad=0.05)\n",
    "# Add the title to the colorbar (acts as the legend heading)\n",
    "cbar.set_label(\"Elevation in feet\")\n",
    "\n",
    "plt.title(\"US Cities Elevation Quantiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation Difference: By dividing the data into quantiles, we can clearly see how the cities are distributed across different elevation ranges. Each quantile represents a subset of the data with similar elevations, allowing us to understand the distribution and density of cities at various elevation levels. This method is effective in highlighting patterns and trends that might be missed if we were to use a single color for all data points or group them without considering the distribution. Based on the output we can conclude that Central US is higher above sea level than the coasts. Western part of the US is more elevated than the eastern part of the ocuntry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Create a Voronoi diagram for the elevations of US cities. Use a data smoothing\n",
    "technique since the elevations are for points, and \"spread\" those values across areas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "from scipy.spatial import Voronoi\n",
    "from shapely.geometry import Polygon, Point\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the usa_cities dataset\n",
    "path = gplt.datasets.get_path(\"usa_cities\")\n",
    "usa_cities = gpd.read_file(path)\n",
    "\n",
    "# Filter for continental US cities\n",
    "continental_usa_cities = usa_cities.query('STATE not in [\"HI\", \"AK\", \"PR\"]')\n",
    "\n",
    "# Extract city coordinates\n",
    "points = np.array([(point.x, point.y) for point in continental_usa_cities.geometry])\n",
    "elevations = continental_usa_cities[\"ELEV_IN_FT\"].to_numpy()\n",
    "\n",
    "# Generate valid Voronoi polygons and associate with elevations\n",
    "vor = Voronoi(points)\n",
    "vor_polygons = []\n",
    "valid_elevations = []\n",
    "\n",
    "for region_idx, elevation in zip(vor.point_region, elevations):\n",
    "    region = vor.regions[region_idx]\n",
    "    if -1 not in region and region:  # Exclude infinite or empty regions\n",
    "        polygon = Polygon([vor.vertices[i] for i in region])\n",
    "        if polygon.is_valid:  # Ensure the polygon is valid\n",
    "            vor_polygons.append(polygon)\n",
    "            valid_elevations.append(elevation)\n",
    "\n",
    "# Create GeoDataFrame with valid polygons and corresponding elevations\n",
    "polygons_with_elevation = gpd.GeoDataFrame(\n",
    "    {\"geometry\": vor_polygons, \"Elevation\": valid_elevations},\n",
    "    crs=continental_usa_cities.crs\n",
    ")\n",
    "\n",
    "# Load US states shapefile and compute boundary\n",
    "us_states = gpd.read_file(gplt.datasets.get_path(\"contiguous_usa\"))\n",
    "us_boundary = us_states.geometry.unary_union\n",
    "\n",
    "# Clip Voronoi polygons to the US border\n",
    "clipped = gpd.overlay(\n",
    "    polygons_with_elevation,\n",
    "    gpd.GeoDataFrame(geometry=[us_boundary], crs=us_states.crs),\n",
    "    how=\"intersection\"\n",
    ")\n",
    "\n",
    "# Plot the Voronoi diagram colored by elevation\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "clipped.plot(column=\"Elevation\", cmap=\"terrain\", ax=ax, legend=True, legend_kwds={'label': \"Elevation (ft)\"})\n",
    "\n",
    "# Plot US state boundaries\n",
    "us_states.boundary.plot(ax=ax, linewidth=1, edgecolor=\"black\", label=\"State Boundaries\")\n",
    "\n",
    "# Plot cities as points\n",
    "continental_usa_cities.plot(ax=ax, color=\"red\", markersize=5, label=\"Cities\")\n",
    "\n",
    "# Add title, legend, and axis labels\n",
    "plt.title(\"Voronoi Diagram for the elevation above sea level in the US, based on cities' elevation data\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(loc=\"upper right\", frameon=True, fontsize=10)\n",
    "\n",
    "# Show grid for better reference of latitude and longitude\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Voronoi diagram displays the region's elevation around cities in the US. Based on the data about each city the Voronoi technique suggests elevation level about larger areas/regions. We have tried to make the visualization self explainatory by describing axis, legend, keeping cities and state boarders in accurate position to eachother etc.\n",
    "\n",
    "As the instructuion was to create a Voronoi diagram for the elevations of US cities the Voronoi diagram might not be the optimal choice to showcase indivudual cities specific elevation. It is hard to see the exact elevation of a city for three reasons. First, a city may be located on the border between two colors. Second, the legend used is based on a continuous color scale rather than based on color associated binning. Third, the Voronoi reveales additional information regarding the area between the cities. Example of an mprovement would be to make the map \"interactable\" so that hoovering over a city data point would give the exact elevation or use anpther visualization technique that points out seperate cities elevation. However, this kind of visualization is very informative when it comes to getting a good overwiew of the elevation of certain specific geograhic points and the elevation's variation. \n",
    "\n",
    "When adding on smoothing geometric buffer we noticed that the size of the colored regions expanded, but not the cities or state boarders. When testing different levels of smoothening, we observed that a too high smoothing level could cause a color overlap that mislead the interpretation of the elevation in the surrounding areas. We therfore, decided to only have a low degree of smooting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Apply the same Covid19 visualization section’s method for visualizing the\n",
    "COVID-19 recovered case dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with recovered global COVID-19 cases\n",
    "df_recoveredGlobal = pd.read_csv(\"..\\\\..\\\\3.4Covid-19\\\\time_series_covid19_recovered_global.csv\")\n",
    "print(df_recoveredGlobal.head())\n",
    "\n",
    "# Remove unnecessary columns and sum by country\n",
    "df_recoveredGlobal = df_recoveredGlobal.drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "df_recoveredGlobal = df_recoveredGlobal.groupby('Country/Region').agg('sum')\n",
    "date_list_recovered = list(df_recoveredGlobal.columns)\n",
    "\n",
    "# Add country codes to the dataset\n",
    "df_recoveredGlobal['country'] = df_recoveredGlobal.index\n",
    "df_recoveredGlobal['iso_alpha_3'] = df_recoveredGlobal['country'].apply(get_country_code)\n",
    "\n",
    "# Transform to long format\n",
    "df_long_recovered = pd.melt(df_recoveredGlobal, \n",
    "                            id_vars=['country', 'iso_alpha_3'], \n",
    "                            value_vars=date_list_recovered)\n",
    "print(df_long_recovered)\n",
    "\n",
    "# Create Map with Plotly Express\n",
    "fig_recovered = px.choropleth(df_long_recovered,\n",
    "                              locations=\"iso_alpha_3\",\n",
    "                              color=\"value\",\n",
    "                              hover_name=\"country\",\n",
    "                              animation_frame=\"variable\",\n",
    "                              projection=\"natural earth\",\n",
    "                              color_continuous_scale='Greens',\n",
    "                              range_color=[0, 50000],\n",
    "                              labels={\"value\": \"Covid-19 Recovered cases\", \"variable\": \"Date\"}\n",
    "                              )\n",
    "\n",
    "fig_recovered.show()\n",
    "fig_recovered.write_html(\"Covid19_recovered_map.html\") # write it to HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map illstrates how the total number of recovered Covid-19 patients evolved around the world over time. It does not take the number of deceased into account, but only the number of recovered in thousands. The graphics concearn the time span from 01/22/2020 to 11/06/2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Apply the same Covid19 visualization section’s method for visualizing the\n",
    "COVID-19 death case dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with global COVID-19 death cases\n",
    "df_deathsGlobal = pd.read_csv(\"..\\\\..\\\\3.4Covid-19\\\\time_series_covid19_deaths_global.csv\")\n",
    "print(df_deathsGlobal.head())\n",
    "\n",
    "# Remove unnecessary columns and sum by country\n",
    "df_deathsGlobal = df_deathsGlobal.drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "df_deathsGlobal = df_deathsGlobal.groupby('Country/Region').agg('sum')\n",
    "date_list_deaths = list(df_deathsGlobal.columns)\n",
    "\n",
    "# Add country codes to the dataset\n",
    "df_deathsGlobal['country'] = df_deathsGlobal.index\n",
    "df_deathsGlobal['iso_alpha_3'] = df_deathsGlobal['country'].apply(get_country_code)\n",
    "\n",
    "# Transform to long format\n",
    "df_long_deaths = pd.melt(df_deathsGlobal, \n",
    "                         id_vars=['country', 'iso_alpha_3'], \n",
    "                         value_vars=date_list_deaths)\n",
    "print(df_long_deaths)\n",
    "\n",
    "# Create Map with Plotly Express\n",
    "fig_deaths = px.choropleth(df_long_deaths,\n",
    "                           locations=\"iso_alpha_3\",\n",
    "                           color=\"value\",\n",
    "                           hover_name=\"country\",\n",
    "                           animation_frame=\"variable\",\n",
    "                           projection=\"natural earth\",\n",
    "                           color_continuous_scale='Reds',\n",
    "                           range_color=[0, 50000],\n",
    "                           labels={\"value\": \"Covid-19 Death cases\", \"variable\": \"Date\"}\n",
    "                           )\n",
    "\n",
    "fig_deaths.show()\n",
    "fig_deaths.write_html(\"C:/Users/emmae/Desktop/DataVisualization_Uppgiftsmapp/Labb2/D7055E-Labb-2/notebooks/Covid19_deaths_map.html\") # write it to HTML file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map illstrates how the total number of deth cases due to Covid-19 evolved around the world over time. It does not take the number of deceased into account, but only the number of dead in thousands. The graphics concearn the time span from 01/22/2020 to 11/06/2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
